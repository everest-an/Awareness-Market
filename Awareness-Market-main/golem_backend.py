"""
Project Golem - å¯é›†æˆçš„Pythonåç«¯æ¨¡å—
ç”¨äºä¸å…¶ä»–é¡¹ç›®é›†æˆçš„å‘é‡æŸ¥è¯¢æœåŠ¡

ä½¿ç”¨æ–¹æ³•:
    from golem_backend import GolemBackend
    
    backend = GolemBackend(
        model_id="google/embedding-gemma-300m",
        vector_file="golem_vectors.npy",
        json_file="golem_cortex.json"
    )
    
    results = backend.query("Julius Caesar")
    print(results)  # {'indices': [...], 'scores': [...]}
"""

import os
import json
import numpy as np
import torch
from typing import Dict, List, Tuple
from sentence_transformers import SentenceTransformer


class GolemBackend:
    """
    Project Golem åç«¯æŸ¥è¯¢æœåŠ¡ç±»
    
    å±æ€§:
        model_id (str): å‘é‡åŒ–æ¨¡å‹ID
        device (str): è®¡ç®—è®¾å¤‡ ('cpu', 'cuda', 'mps')
        memory_matrix (np.ndarray): å‘é‡çŸ©é˜µ
        cortex_data (list): èŠ‚ç‚¹æ•°æ®
        model (SentenceTransformer): å‘é‡åŒ–æ¨¡å‹å®ä¾‹
    """
    
    def __init__(self, 
                 model_id: str = "google/embedding-gemma-300m",
                 vector_file: str = "golem_vectors.npy",
                 json_file: str = "golem_cortex.json",
                 device: str = None,
                 trust_remote_code: bool = True):
        """
        åˆå§‹åŒ–GolemBackend
        
        å‚æ•°:
            model_id: å‘é‡åŒ–æ¨¡å‹ID (é»˜è®¤: google/embedding-gemma-300m)
            vector_file: å‘é‡çŸ©é˜µæ–‡ä»¶è·¯å¾„
            json_file: èŠ‚ç‚¹æ•°æ®JSONæ–‡ä»¶è·¯å¾„
            device: è®¡ç®—è®¾å¤‡('cpu', 'cuda', 'mps', è‡ªåŠ¨æ£€æµ‹)
            trust_remote_code: æ˜¯å¦ä¿¡ä»»è¿œç¨‹ä»£ç 
        """
        
        self.model_id = model_id
        self.vector_file = vector_file
        self.json_file = json_file
        self.trust_remote_code = trust_remote_code
        
        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        if device is None:
            self.device = self._detect_device()
        else:
            self.device = device
        
        print(f"ğŸ§  GolemBackend Initialization")
        print(f"   ğŸ“Š Model: {model_id}")
        print(f"   ğŸ’» Device: {self.device.upper()}")
        
        # åŠ è½½æ•°æ®
        self.memory_matrix = None
        self.cortex_data = None
        self.model = None
        
        self._load_resources()
    
    @staticmethod
    def _detect_device() -> str:
        """è‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„è®¡ç®—è®¾å¤‡"""
        if torch.cuda.is_available():
            return "cuda"
        elif torch.backends.mps.is_available():
            return "mps"
        else:
            return "cpu"
    
    def _load_resources(self):
        """åŠ è½½å‘é‡çŸ©é˜µã€èŠ‚ç‚¹æ•°æ®å’Œæ¨¡å‹"""
        
        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(self.vector_file):
            raise FileNotFoundError(f"Vector file not found: {self.vector_file}")
        if not os.path.exists(self.json_file):
            raise FileNotFoundError(f"JSON file not found: {self.json_file}")
        
        # åŠ è½½å‘é‡çŸ©é˜µ
        print(f"   â†³ Loading memory matrix from {self.vector_file}...")
        self.memory_matrix = np.load(self.vector_file)
        
        # è§„èŒƒåŒ–å‘é‡çŸ©é˜µ
        norm = np.linalg.norm(self.memory_matrix, axis=1, keepdims=True)
        self.memory_matrix = self.memory_matrix / norm
        print(f"      âœ“ Shape: {self.memory_matrix.shape}")
        
        # åŠ è½½èŠ‚ç‚¹æ•°æ®
        print(f"   â†³ Loading cortex data from {self.json_file}...")
        with open(self.json_file, 'r') as f:
            self.cortex_data = json.load(f)
        print(f"      âœ“ Nodes: {len(self.cortex_data)}")
        
        # åŠ è½½æ¨¡å‹
        print(f"   â†³ Loading model {self.model_id}...")
        self.model = SentenceTransformer(
            self.model_id,
            device=self.device,
            trust_remote_code=self.trust_remote_code
        )
        print(f"      âœ“ Model loaded successfully")
        print(f"   âœ… GolemBackend ready\n")
    
    def query(self, 
              text: str, 
              top_k: int = 50,
              min_score: float = None) -> Dict[str, List]:
        """
        æŸ¥è¯¢å‘é‡æ•°æ®åº“
        
        å‚æ•°:
            text: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›çš„å‰Kä¸ªç»“æœæ•°é‡ (é»˜è®¤: 50)
            min_score: æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼ (å¯é€‰)
        
        è¿”å›:
            {
                'indices': [èŠ‚ç‚¹ç´¢å¼•åˆ—è¡¨],
                'scores': [ç›¸ä¼¼åº¦åˆ†æ•°åˆ—è¡¨],
                'nodes': [å®Œæ•´èŠ‚ç‚¹æ•°æ®åˆ—è¡¨]
            }
        """
        
        if not text or not text.strip():
            return {'indices': [], 'scores': [], 'nodes': []}
        
        # å‘é‡åŒ–æŸ¥è¯¢æ–‡æœ¬
        query_vec = self.model.encode(
            [f"Represent this query for retrieval: {text}"],
            convert_to_numpy=True
        )[0]
        
        # ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—
        scores = np.dot(self.memory_matrix, query_vec)
        
        # è·å–å‰Kä¸ªç»“æœ
        top_indices = np.argsort(scores)[-top_k:][::-1]
        top_scores = scores[top_indices]
        
        # å¯é€‰çš„é˜ˆå€¼è¿‡æ»¤
        if min_score is not None:
            mask = top_scores >= min_score
            top_indices = top_indices[mask]
            top_scores = top_scores[mask]
        
        # è·å–å®Œæ•´èŠ‚ç‚¹æ•°æ®
        nodes = [self.cortex_data[idx] for idx in top_indices]
        
        return {
            'indices': top_indices.tolist(),
            'scores': top_scores.tolist(),
            'nodes': nodes
        }
    
    def query_advanced(self,
                      text: str,
                      top_k: int = 50,
                      category_filter: str = None,
                      min_score: float = None) -> Dict:
        """
        é«˜çº§æŸ¥è¯¢å‡½æ•°ï¼Œæ”¯æŒåˆ†ç±»è¿‡æ»¤
        
        å‚æ•°:
            text: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›çš„å‰Kä¸ªç»“æœ
            category_filter: æŒ‰åˆ†ç±»è¿‡æ»¤ (Noneè¡¨ç¤ºä¸è¿‡æ»¤)
            min_score: æœ€å°ç›¸ä¼¼åº¦
        
        è¿”å›:
            åŒ…å«è¿‡æ»¤åç»“æœçš„å­—å…¸
        """
        
        result = self.query(text, top_k=top_k*2, min_score=min_score)
        
        # åˆ†ç±»è¿‡æ»¤
        if category_filter:
            filtered_indices = []
            filtered_scores = []
            filtered_nodes = []
            
            for idx, score, node in zip(result['indices'], result['scores'], result['nodes']):
                if node.get('cat') == category_filter:
                    filtered_indices.append(idx)
                    filtered_scores.append(score)
                    filtered_nodes.append(node)
                
                if len(filtered_indices) >= top_k:
                    break
            
            result = {
                'indices': filtered_indices,
                'scores': filtered_scores,
                'nodes': filtered_nodes
            }
        else:
            # ä»…ä¿ç•™å‰Kä¸ª
            result = {
                'indices': result['indices'][:top_k],
                'scores': result['scores'][:top_k],
                'nodes': result['nodes'][:top_k]
            }
        
        return result
    
    def batch_query(self, 
                   texts: List[str], 
                   top_k: int = 10) -> List[Dict]:
        """
        æ‰¹é‡æŸ¥è¯¢
        
        å‚æ•°:
            texts: æŸ¥è¯¢æ–‡æœ¬åˆ—è¡¨
            top_k: æ¯ä¸ªæŸ¥è¯¢è¿”å›çš„ç»“æœæ•°
        
        è¿”å›:
            æŸ¥è¯¢ç»“æœåˆ—è¡¨
        """
        
        return [self.query(text, top_k=top_k) for text in texts]
    
    def get_node(self, index: int) -> Dict:
        """è·å–æŒ‡å®šç´¢å¼•çš„èŠ‚ç‚¹æ•°æ®"""
        if 0 <= index < len(self.cortex_data):
            return self.cortex_data[index]
        return None
    
    def get_all_nodes(self) -> List[Dict]:
        """è·å–æ‰€æœ‰èŠ‚ç‚¹æ•°æ®"""
        return self.cortex_data
    
    def get_nodes_by_category(self, category: str) -> List[Dict]:
        """è·å–æŒ‡å®šåˆ†ç±»çš„æ‰€æœ‰èŠ‚ç‚¹"""
        return [node for node in self.cortex_data if node.get('cat') == category]
    
    def get_categories(self) -> List[str]:
        """è·å–æ‰€æœ‰åˆ†ç±»"""
        categories = set()
        for node in self.cortex_data:
            if 'cat' in node:
                categories.add(node['cat'])
        return sorted(list(categories))
    
    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        categories = {}
        for node in self.cortex_data:
            cat = node.get('cat', 'Unknown')
            categories[cat] = categories.get(cat, 0) + 1
        
        return {
            'total_nodes': len(self.cortex_data),
            'categories': categories,
            'vector_dimension': self.memory_matrix.shape[1],
            'model_id': self.model_id,
            'device': self.device
        }
    
    def search_by_title(self, title_query: str) -> List[Dict]:
        """æŒ‰æ ‡é¢˜æœç´¢èŠ‚ç‚¹"""
        results = []
        query_lower = title_query.lower()
        
        for node in self.cortex_data:
            if query_lower in node.get('title', '').lower():
                results.append(node)
        
        return results
    
    def get_neighbors(self, node_index: int, k: int = 8) -> List[Dict]:
        """è·å–èŠ‚ç‚¹çš„é‚»å±…"""
        node = self.get_node(node_index)
        if not node:
            return []
        
        neighbor_indices = node.get('nbs', [])[:k]
        return [self.get_node(idx) for idx in neighbor_indices if self.get_node(idx)]


# ==================== Flaské›†æˆç¤ºä¾‹ ====================

def create_flask_app(backend: GolemBackend):
    """
    åˆ›å»ºFlaskåº”ç”¨ï¼Œé›†æˆGolemBackend
    
    ä½¿ç”¨æ–¹æ³•:
        backend = GolemBackend()
        app = create_flask_app(backend)
        app.run(port=8000)
    """
    from flask import Flask, request, jsonify
    
    app = Flask(__name__)
    
    @app.route('/query', methods=['POST'])
    def query_endpoint():
        """æŸ¥è¯¢ç«¯ç‚¹"""
        try:
            data = request.json
            query_text = data.get('query', '')
            top_k = data.get('top_k', 50)
            min_score = data.get('min_score', None)
            
            result = backend.query(query_text, top_k=top_k, min_score=min_score)
            
            return jsonify({
                'success': True,
                'indices': result['indices'],
                'scores': result['scores']
            })
        except Exception as e:
            return jsonify({
                'success': False,
                'error': str(e)
            }), 400
    
    @app.route('/query/advanced', methods=['POST'])
    def query_advanced_endpoint():
        """é«˜çº§æŸ¥è¯¢ç«¯ç‚¹"""
        try:
            data = request.json
            result = backend.query_advanced(
                text=data.get('query', ''),
                top_k=data.get('top_k', 50),
                category_filter=data.get('category', None),
                min_score=data.get('min_score', None)
            )
            
            return jsonify({
                'success': True,
                'indices': result['indices'],
                'scores': result['scores'],
                'nodes': result['nodes']
            })
        except Exception as e:
            return jsonify({
                'success': False,
                'error': str(e)
            }), 400
    
    @app.route('/node/<int:index>', methods=['GET'])
    def get_node_endpoint(index):
        """è·å–èŠ‚ç‚¹ä¿¡æ¯"""
        node = backend.get_node(index)
        if node:
            return jsonify({'success': True, 'node': node})
        return jsonify({'success': False, 'error': 'Node not found'}), 404
    
    @app.route('/categories', methods=['GET'])
    def get_categories_endpoint():
        """è·å–æ‰€æœ‰åˆ†ç±»"""
        return jsonify({
            'success': True,
            'categories': backend.get_categories()
        })
    
    @app.route('/statistics', methods=['GET'])
    def get_statistics_endpoint():
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return jsonify({
            'success': True,
            'statistics': backend.get_statistics()
        })
    
    @app.route('/health', methods=['GET'])
    def health_check():
        """å¥åº·æ£€æŸ¥"""
        return jsonify({
            'success': True,
            'status': 'healthy',
            'nodes': len(backend.cortex_data)
        })
    
    return app


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

if __name__ == "__main__":
    # åˆå§‹åŒ–åç«¯
    backend = GolemBackend(
        model_id="google/embedding-gemma-300m",
        vector_file="golem_vectors.npy",
        json_file="golem_cortex.json"
    )
    
    # ç¤ºä¾‹1: ç®€å•æŸ¥è¯¢
    print("ğŸ“Š æŸ¥è¯¢ç¤ºä¾‹:")
    result = backend.query("Julius Caesar", top_k=5)
    print(f"   æ‰¾åˆ° {len(result['indices'])} ä¸ªç»“æœ")
    for i, node in enumerate(result['nodes'][:3]):
        print(f"   {i+1}. {node['title']} ({node['cat']}) - ç›¸ä¼¼åº¦: {result['scores'][i]:.4f}")
    
    # ç¤ºä¾‹2: åˆ†ç±»è¿‡æ»¤
    print("\nğŸ“‚ æŒ‰åˆ†ç±»è¿‡æ»¤:")
    categories = backend.get_categories()
    print(f"   å¯ç”¨åˆ†ç±»: {', '.join(categories)}")
    
    # ç¤ºä¾‹3: ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
    stats = backend.get_statistics()
    for cat, count in stats['categories'].items():
        print(f"   {cat}: {count}")
    
    # ç¤ºä¾‹4: å¯åŠ¨Flaskåº”ç”¨
    print("\nğŸš€ å¯åŠ¨Flaskåº”ç”¨...")
    app = create_flask_app(backend)
    app.run(port=8000, debug=False)
